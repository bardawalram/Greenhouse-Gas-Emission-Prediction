# ğŸŒ± Greenhouse Gas Emission Prediction (2010â€“2016)

A complete Machine Learning project that predicts **Supply Chain Emission Factors with Margins** using multi-year industry and commodity emission datasets.  
The project includes dataset merging, preprocessing, model training, evaluation, and a deployed Streamlit web application.

---

## ğŸ“Œ Project Overview
This project uses a multi-sheet Excel dataset containing emission data from **2010 to 2016**.  
Each year in the dataset includes two sheets:

- <year>_Detail_Commodity  
- <year>_Detail_Industry  

The main goal is to:
- Merge these sheets year-wise  
- Clean and standardize the data  
- Build and evaluate regression models  
- Deploy a prediction interface using Streamlit  

---

## ğŸ¯ Objectives
- Understand and visualize greenhouse gas emission patterns  
- Clean and preprocess multi-year Excel data  
- Apply feature engineering and data encoding  
- Train and evaluate regression models  
- Deploy the model using Streamlit for real-time predictions  

---

## ğŸ› ï¸ Technologies Used

### Programming Language
- Python

### Libraries
- pandas  
- numpy  
- scikit-learn  
- matplotlib  
- seaborn  
- joblib  
- Streamlit  

### Tools
- Jupyter Notebook  
- VS Code  

---

## ğŸ“‚ Dataset Structure
The dataset contains two sheets for each year from 2010 to 2016:

2010_Detail_Commodity
2010_Detail_Industry
2011_Detail_Commodity
2011_Detail_Industry
...
2016_Detail_Commodity
2016_Detail_Industry

markdown
Copy code

Each sheet includes:
- Code  
- Name  
- Substance  
- Unit  
- Reliability  
- Temporal Correlation  
- Geographical Correlation  
- Technological Correlation  
- Emission Factor  

---

## ğŸ”„ Data Processing Pipeline

### âœ… 1. Load Data
Read Commodity and Industry sheets for every year.

### âœ… 2. Add Metadata Columns
Add additional columns:
- `Source` (Commodity / Industry)  
- `Year` (2010â€“2016)  

### âœ… 3. Clean Column Names
Remove extra whitespace and standardize:
- Commodity Code â†’ Code  
- Industry Code â†’ Code  
- Commodity Name â†’ Name  
- Industry Name â†’ Name  

### âœ… 4. Merge Commodity & Industry Data
Combine commodity and industry datasets for each year using `pd.concat`.

### âœ… 5. Combine All Years
Merge all years into a single final dataframe:

df = pd.concat(all_data, ignore_index=True)

sql
Copy code

### âœ… 6. Remove Unnecessary Columns
Drop empty or irrelevant columns like:

df.drop(columns=['Unnamed: 7'], inplace=True)

markdown
Copy code

### âœ… 7. Data Preprocessing
- Handle missing values  
- Encode categorical variables  
- Scale numerical features  

### âœ… 8. Model Training
Train ML regression models:
- Linear Regression  
- Random Forest Regressor  

### âœ… 9. Model Evaluation
Evaluate using:
- RÂ² Score  
- Mean Absolute Error (MAE)  
- Root Mean Squared Error (RMSE)  

### âœ… 10. Save Trained Model
Save the final model using joblib:

joblib.dump(model, "ghg_model.pkl")

yaml
Copy code

---

## ğŸš€ Streamlit Application

The Streamlit app allows users to input:
- Substance  
- Unit  
- Reliability  
- Temporal / Geographical / Technological correlations  
- Code or Name  

The app outputs:
âœ… **Predicted Supply Chain Emission Factor with Margin**

Run the app using:

streamlit run app.py

yaml
Copy code

---

## ğŸ“Š Visualizations Included
- Year-wise emission trends  
- Correlation heatmaps  
- Distribution plots  
- Feature importance (Random Forest)  

---

## ğŸ“ Recommended Project Structure

GHG-Emission-Prediction
â”‚ README.md
â”‚ requirements.txt
â”‚ data/
â”‚ SupplyChainEmissionFactorsforUSIndustriesCommodities.xlsx
â”‚ notebooks/
â”‚ data_cleaning.ipynb
â”‚ models/
â”‚ ghg_model.pkl
â”‚ app/
â”‚ app.py

yaml
Copy code

---

## âœ¨ Key Features
- Multi-year, multi-sheet dataset integration  
- Clean and efficient preprocessing pipeline  
- Regression model with strong interpretability  
- Fully functional Streamlit prediction interface  

---
